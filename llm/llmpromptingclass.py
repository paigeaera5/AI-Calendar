from torch import cuda
import transformers
import time

def convert_seconds(seconds):
    hours = seconds // 3600
    seconds %= 3600
    minutes = seconds // 60
    seconds %= 60
    return hours, minutes, seconds


class LLMPrompter:

    model_id = 'meta-llama/Llama-2-7b-chat-hf'
    device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'

    # Llama 2 Tokenizer
    tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)

    # Llama 2 Model
    model = transformers.AutoModelForCausalLM.from_pretrained(
        model_id,
        trust_remote_code=True,
        device_map='auto'
    )

    # Pipeline using Transformers
    generator = transformers.pipeline(
        model=model, tokenizer=tokenizer,
        task='text-generation',
        temperature=0.1,
        max_new_tokens=1000,
        repetition_penalty=1.1
    )

    def __init__(self, task: str, num_steps: int, length: str, hours_per_day: int):

        """
        Initializes a new LLMPrompter object based off a given task
        to break down, length, and other information

        Arguments:
        task           - string of the task to break down
        num_steps      - int number of steps to break task into (in a one month duration)
        length         - length of task to complete as a string ("one month", "2 weeks", etc.)
        hours_per_day  - int maximum number of hours to spend on task on a given day

        """

        self.task = task
        self.steps = num_steps
        self.length = length
        self.hours_per_day = hours_per_day
        self.events = []
        self.event_descriptions = []

        # Main prompt to generate response off of
        main_prompt = f"""
        [INST]
        Given a large task, break this task down into EXACTLY {num_steps} step-by-step smaller tasks (no more, no less) that are more manageable. Your response should be in a numbered format, where each number lists the name of each smaller task (in three to five words) 
        and includes the time it would take to complete the respective smaller task. Limit each smaller task to take a maximum of {hours_per_day} hours time to complete, no more.
        

        Here is your large task to break down: {task} in {length}

        Based on the large task provided above, please create a set of numbered smaller sub-tasks, with the approximate time it takes to complete each sub-task in parentheses. If you cannot generate {num_steps} tasks, repeat tasks as needed to reach the exact amount of sub-tasks ({num_steps}) required.
        Make sure you to only return the list of smaller tasks, times, and nothing more.
        
        [/INST]
        """

        self.prompt = main_prompt

        """
        The following code generates and returns the response generated by the LLM based
        on the prompt inputted during initialization.
        Populates the events array with the generated sub-tasks

        """

        # Record start time
        start_time = time.time()

        res = self.generator(self.prompt)

        # Record end time
        end_time = time.time()

        hours, minutes, seconds = convert_seconds(end_time - start_time)
        print(f"Elapsed time to generate sub-tasks: {hours} hours, {minutes} minutes, and {seconds} seconds")

        # if prompt is in final response, removes the prompt from it
        self.response = ""
        if self.prompt in res[0]["generated_text"]:
            self.response = res[0]["generated_text"].replace(self.prompt, "")
        

        # the following code determines if repetition of generated events is necessary (we repeat events if the
        # length provided is longer than one month, and we repeat events monthly)
        iter = 1
        if "month" in self.length:
            iter = int(self.length[0])

        for j in range(iter):
            for i in range(1, self.steps + 1):
                if i != self.steps:
                    ind1 = self.response.index(str(i) + ". ") + 3
                    ind2 = self.response.index("\n" + str(i + 1) + ". ")
                    self.events.append(self.response[ind1:ind2])
                else:
                    ind1 = self.response.index(str(i) + ". ") + 3
                    self.events.append(self.response[ind1:])

        """
        Generates and returns the event description of a given event
        in the events array

        Arguments:
        event_number  - int event number of the event to generate description of (one-indexed)

        Returns: string event description generated by LLM based on given event number

        """
        
        for i in range(self.steps):
            desc_prompt = f"""
                [INST]
                Given a calendar event name, generate a short but descriptive description of the calendar event (no more than five sentences). Your description should be easily digestible to all.

                Here is the event name: {self.events[i]}

                Based on the name above, generate a description that follows the guidelines above. Your response should contain the description and nothing else.
                [/INST]
                        """
                
            # Record start time
            start_time = time.time()

            res = self.generator(desc_prompt)

            # Record end time
            end_time = time.time()

            hours, minutes, seconds = convert_seconds(end_time - start_time)
            print(f"Elapsed time to generate description: {hours} hours, {minutes} minutes, and {seconds} seconds")

            # if prompt is in final response, removes the prompt from it
            response = ""
            if desc_prompt in res[0]["generated_text"]:
                response = res[0]["generated_text"].replace(desc_prompt, "")

            if "\n" in response:
                response = response[response.index("\n") + 1:]

            self.event_descriptions.append(response)

        for i in range(self.steps, len(self.events)):
            self.event_descriptions.append(self.event_descriptions[i % self.steps])
        





    """
    def generate_subtasks(self):

        
        Generates and returns the response generated by the LLM based
        on the prompt inputted during initialization.
        Populates the events array with the generated sub-tasks

        Arguments: None

        Returns: complete response given by Llama2 LLM (string)

        


        # Record start time
        start_time = time.time()

        res = self.generator(self.prompt)

        # Record end time
        end_time = time.time()

        hours, minutes, seconds = convert_seconds(end_time - start_time)
        print(f"Elapsed time to generate sub-tasks: {hours} hours, {minutes} minutes, and {seconds} seconds")

        # if prompt is in final response, removes the prompt from it
        response = ""
        if self.prompt in res[0]["generated_text"]:
            response = res[0]["generated_text"].replace(self.prompt, "")
        

        # the following code determines if repetition of generated events is necessary (we repeat events if the
        # length provided is longer than one month, and we repeat events monthly)
        iter = 1
        if "month" in self.length:
            iter = int(self.length[0])

        for j in range(iter):
            for i in range(1, self.steps + 1):
                if i != self.steps:
                    ind1 = response.index(str(i) + ". ") + 3
                    ind2 = response.index("\n" + str(i + 1) + ". ")
                    self.events.append(response[ind1:ind2])
                else:
                    ind1 = response.index(str(i) + ". ") + 3
                    self.events.append(response[ind1:])

        return response
    
    def generate_event_description(self, event_number: int):

        
        Generates and returns the event description of a given event
        in the events array

        Arguments:
        event_number  - int event number of the event to generate description of (one-indexed)

        Returns: string event description generated by LLM based on given event number 

        if len(self.events) == 0:  # means user hasn't run generate_subtasks() yet
            print("Make sure to run generate_subtasks first!")
        elif event_number > len(self.events) or event_number < 1:  # branch when event number given is out of bounds
            print("Event number out of bounds")
        else:  # code to generate an event description from the sub-task indexed in the events array
            # Prompt for generating event description
            desc_prompt = f
                [INST]
                Given a calendar event name, generate a short but descriptive description of the calendar event (no more than five sentences). Your description should be easily digestible to all.

                Here is the event name: {self.events[event_number - 1]}

                Based on the name above, generate a description that follows the guidelines above. Your response should contain the description and nothing else.
                [/INST]
                          
            
            # Record start time
            start_time = time.time()

            res = self.generator(desc_prompt)

            # Record end time
            end_time = time.time()

            hours, minutes, seconds = convert_seconds(end_time - start_time)
            print(f"Elapsed time to generate description: {hours} hours, {minutes} minutes, and {seconds} seconds")

            # if prompt is in final response, removes the prompt from it
            response = ""
            if desc_prompt in res[0]["generated_text"]:
                response = res[0]["generated_text"].replace(desc_prompt, "")

            if "\n" in response:
                response = response[response.index("\n") + 1:]
            
            return response
"""
    

if __name__ == "__main__":
    prompt1 = LLMPrompter("Training for running a marathon starting with no experience", 12, "4 months", 3)
    # prompt2 = LLMPrompter("Study for a Linear Algebra midterm (topics covered include LU decomposition, change of bases, linear transformations)", 7, "1 week", 2)

    print("Event names:\n\n")
    print(prompt1.events)

    print("_____________________________________________________________________________________________________________________________\n")
    print("Event descriptions:\n\n")
    print(prompt1.event_descriptions)
    '''
    prompt2.generate_subtasks()

    print(f"_____________________________________________________________________________________________________________________________\nPrompt 2: {prompt2.task}")
    
    print("Number of events: " + str(len(prompt2.events)))
    for i in range(len(prompt2.events)):
        print(str(i+1) + ". " + prompt2.events[i])

    '''
    
